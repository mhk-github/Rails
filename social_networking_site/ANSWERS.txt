1. GIL - Global Interpreter Lock

The GIL allows only one thread to run in a process at a time on a computer's 
Central Processing Unit (CPU).

A process can have multiple threads. Each is capable of performing the same 
or different tasks and they all share the same memory of the process. Threads 
improve responsiveness as while a process needs one thread to complete some 
task, another can run productively. Since they share the process's memory, 
however, threads need to be synchronized and scheduled correctly so that any 
writes to memory are seen consistently by all threads. 

Modern CPUs can run several processes and threads simultaneously. Programs 
like Ruby were written leveraging code written before multithreading was 
commonplace. That code is often not thread-safe due to how it writes to memory 
when running. The workaround is to permit only one thread at a time to run in 
a process on the CPU. That is achieved by it holding the GIL while it runs, 
releasing it when its work is done. Other threads wait to receive the GIL before 
they can run.

When scaling a production application, the GIL needs to be considered. A 
multithreading CPU-intensive process will face the GIL issue even if the CPU is 
upgraded. If, however, it can be changed from multithreading to multiprocess 
then there is no GIL issue since processes each have their own memory space 
unlike threads. Also, the GIL is not an issue if a multithreading process is 
waiting for data from a network. In that case an active thread can be set to 
sleep while it waits and the GIL released to another thread. 

2. Background Job Queuing Service

Just like threads, a background job queuing service can improve application 
responsiveness.

Some activities an application undertakes can be CPU-intensive or 
network-intensive. Examples are applications needing masses of data from remote 
sites brought in by API calls, or rendering vast amounts of 3D graphics data. If 
it waits on each time-consuming task to complete before starting the next one, 
the application's responsiveness decreases. An effective solution is to parcel 
those time-consuming activities into distinct jobs, send those to a queue, then 
move on to the next task. The queue is First-In-First-Out (FIFO), meaning jobs 
can be processed in the order they arrived in. A different process or thread can 
deal with these jobs, notifying the application once each is completed. It can 
run in the background at a low priority so as to make the main application more 
responsiveness to its main tasks.
